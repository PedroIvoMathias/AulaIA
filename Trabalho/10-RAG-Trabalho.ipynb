{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "677b7e64",
   "metadata": {},
   "source": [
    "# Laboratório RAG com LangChain, Groq e Pinecone"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "361c7b54",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "Este notebook demonstra a implementação de um sistema Retrieval-Augmented Generation (RAG) utilizando a biblioteca LangChain, modelos de linguagem da Groq e o Pinecone como banco de dados vetorial. O objetivo é responder a perguntas com base em documentos PDF fornecidos, focando em atividades físicas e musculação."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "483f54d5",
   "metadata": {},
   "source": [
    "## Configuração do Ambiente"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f84b8f8a",
   "metadata": {},
   "source": [
    "### Importar bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84d52f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "from langchain_core.documents import Document\n",
    "from langchain.chains.router import RouterChain, MultiPromptChain\n",
    "from pydantic import BaseModel\n",
    "from langchain.prompts import PromptTemplate\n",
    "from pydantic.v1 import BaseModel\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a83074c",
   "metadata": {},
   "source": [
    "### Configuração das Chaves de API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5d2ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import find_dotenv, load_dotenv\n",
    "\n",
    "load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d53d26e",
   "metadata": {},
   "source": [
    "## Carregando a LLM da Groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102e76c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGroq(model_name='llama-3.3-70b-versatile',temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124f9981",
   "metadata": {},
   "source": [
    "### Inicializar modelo de embeddings (HuggingFace para uso local/gratuito)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006b6023",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a60c9b7",
   "metadata": {},
   "source": [
    "## Carregamento e Processamento os dados em 'data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156703b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_path = 'data/sample_places.json'\n",
    "\n",
    "#Carregar o JSON com os dados\n",
    "with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea574d2c",
   "metadata": {},
   "source": [
    "### Leitura dos dados que transforma os dados do documento em um documento LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a95b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = []\n",
    "for item in data:\n",
    "    content = f\"{item['name']} ({item['city']}) - {item['type']}\\n{item['description']}\\nDicas: {item['tips']}\"\n",
    "    metadata = {\"city\": item[\"city\"], \"type\": item[\"type\"], \"name\": item[\"name\"]}\n",
    "    documents.append(Document(page_content=content, metadata=metadata))\n",
    "\n",
    "print(f\"Total de documentos: {len(documents)}\")\n",
    "print(documents[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f551dfb5",
   "metadata": {},
   "source": [
    "## Geração de Embeddings e Armazenamento no Pinecone"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135f3558",
   "metadata": {},
   "source": [
    "### Divisão dos Documentos em Chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "074e0023",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "docs = text_splitter.split_documents(documents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd817a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Total de chunks: {len(docs)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18fff2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abfc4a5b",
   "metadata": {},
   "source": [
    "### Inicializar Pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512a0ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc = Pinecone(api_key=os.environ.get(\"PINECONE_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2811a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_name = \"rag-turismo\" \n",
    "existing_indexes = [index_info[\"name\"] for index_info in pc.list_indexes()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e56649",
   "metadata": {},
   "source": [
    "### Deletar e recriar o índice para garantir que a dimensão esteja correta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16549a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "if index_name in existing_indexes:\n",
    "    print(f\"Deletando o índice existente '{index_name}'...\")\n",
    "    pc.delete_index(index_name)\n",
    "    time.sleep(1) # Aguardar a exclusão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa15708",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc.create_index(\n",
    "    name=index_name,\n",
    "    metric=\"cosine\",\n",
    "    dimension=384,\n",
    "    spec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\")\n",
    ")\n",
    "while not pc.describe_index(index_name).status[\"ready\"]:\n",
    "    print(\"Aguardando o índice ficar pronto...\"+pc.describe_index(index_name).status)\n",
    "    time.sleep(1)\n",
    "\n",
    "index = pc.Index(index_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c2151a",
   "metadata": {},
   "source": [
    "### Criar ou conectar ao VectorStore do Pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7548db",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = PineconeVectorStore.from_documents(\n",
    "    documents=docs,\n",
    "    embedding=embeddings,\n",
    "    index_name=index_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e78023bc",
   "metadata": {},
   "source": [
    "## Construção da Cadeia RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8618c261",
   "metadata": {},
   "source": [
    "#### Definir o prompt para a LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde26ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"\"\"Você é um assistente de turismo.\n",
    "Responda à pergunta do usuário **somente** com base no contexto fornecido.\n",
    "Se não souber, diga que não sabe e não invente.\n",
    "\n",
    "Contexto: {context}\n",
    "\n",
    "Pergunta: {input}\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7136b199",
   "metadata": {},
   "source": [
    "### Criar a cadeia de documentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e447af11",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_chain = create_stuff_documents_chain(llm, prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d996a07c",
   "metadata": {},
   "source": [
    "### Criar a cadeia de recuperação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa259fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieval_chain = create_retrieval_chain(vectorstore.as_retriever(), document_chain)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d742d6",
   "metadata": {},
   "source": [
    "## Testando o Sistema RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23717504",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para fazer perguntas\n",
    "def ask_question(question):\n",
    "    response = retrieval_chain.invoke({\"input\": question})\n",
    "    print(f\"Pergunta: {question}\")\n",
    "    print(f\"Resposta: {response['answer']}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6828f4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exemplos de perguntas (use os prompts e perguntas de teste )\n",
    "\n",
    "pergunta1 = \"Quais são os principais pontos turísticos do Rio de Janeiro?\"\n",
    "\n",
    "pergunta2 = \"Dê dicas de segurança para quem vai visitar a Praia de Copacabana.\"\n",
    "\n",
    "pergunta3 = \"Como evitar filas para visitar a Torre Eiffel em Paris?\"\n",
    "\n",
    "pergunta4 = \"O que posso ver no Museu do Louvre?\"\n",
    "\n",
    "pergunta5 = \"Sugira um roteiro cultural de 3 dias em Paris.\"\n",
    "\n",
    "pergunta6 = \"Quais restaurantes ou dicas gastronômicas estão disponíveis no Rio de Janeiro?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e93855",
   "metadata": {},
   "outputs": [],
   "source": [
    "ask_question(pergunta5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a24ac0",
   "metadata": {},
   "source": [
    "### Testando com entrada interativa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be19b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    question = input(\"\\nDigite sua pergunta sobre turismo (ou 'sair' para encerrar): \")\n",
    "    if question.lower() == \"sair\":\n",
    "        break\n",
    "    response = retrieval_chain.invoke({\"input\": question})\n",
    "    print(f\"Resposta: {response['answer']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a508ed",
   "metadata": {},
   "source": [
    "## Criando as cadeias especialziadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473a4a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain.chains import LLMChain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04cb0682",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cadeias que usam RAG\n",
    "itinerary_chain = retrieval_chain\n",
    "logistics_chain = retrieval_chain\n",
    "local_info_chain = retrieval_chain\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Você é um guia de tradução para turistas. Responda com frases úteis e traduções claras.\"),\n",
    "    (\"human\", \"{input}\")\n",
    "])\n",
    "\n",
    "translation_chain = LLMChain(llm=llm, prompt=chat_prompt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97144337",
   "metadata": {},
   "source": [
    "### Criar Router Chain e MultiPromptChai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9b3f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "Classifique a seguinte pergunta em uma das categorias:\n",
    "- roteiro-viagem\n",
    "- logistica-transporte\n",
    "- info-local\n",
    "- traducao-idiomas\n",
    "\n",
    "Pergunta: {input}\n",
    "Categoria:\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b399c99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "router_chain = LLMChain(llm=llm, prompt=prompt)\n",
    "\n",
    "default_chain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=PromptTemplate.from_template(\"Desculpe, não entendi: {input}\")\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891f1359",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7ab88899",
   "metadata": {},
   "source": [
    "### Célula abaixo dando erro e não sendo possível resolver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df7b78b8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'LLMChain' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 13\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#multi_chain = MultiPromptChain(\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#    router_chain=router_chain,\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m#    destination_chains={\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m#    default_chain=LLMChain(llm=llm, prompt=PromptTemplate.from_template(\"Desculpe, não entendi: {input}\"))\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m#)\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m default_chain \u001b[38;5;241m=\u001b[39m LLMChain(\n\u001b[0;32m     14\u001b[0m     llm\u001b[38;5;241m=\u001b[39mllm,\n\u001b[0;32m     15\u001b[0m     prompt\u001b[38;5;241m=\u001b[39mPromptTemplate\u001b[38;5;241m.\u001b[39mfrom_template(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDesculpe, não entendi: \u001b[39m\u001b[38;5;132;01m{input}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     16\u001b[0m )\n\u001b[0;32m     18\u001b[0m destination_chains \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mroteiro-viagem\u001b[39m\u001b[38;5;124m\"\u001b[39m: itinerary_chain,\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogistica-transporte\u001b[39m\u001b[38;5;124m\"\u001b[39m: logistics_chain,\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minfo-local\u001b[39m\u001b[38;5;124m\"\u001b[39m: local_info_chain,\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtraducao-idiomas\u001b[39m\u001b[38;5;124m\"\u001b[39m: translation_chain,\n\u001b[0;32m     23\u001b[0m }\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# Roteador baseado em chave\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'LLMChain' is not defined"
     ]
    }
   ],
   "source": [
    "#multi_chain = MultiPromptChain(\n",
    "#    router_chain=router_chain,\n",
    "#    destination_chains={\n",
    "#        \"roteiro-viagem\": itinerary_chain,\n",
    "#        \"logistica-transporte\": logistics_chain,\n",
    "#        \"info-local\": local_info_chain,\n",
    "#        \"traducao-idiomas\": translation_chain,\n",
    "#    },\n",
    "#    default_chain=LLMChain(llm=llm, prompt=PromptTemplate.from_template(\"Desculpe, não entendi: {input}\"))\n",
    "#)\n",
    "\n",
    "\n",
    "default_chain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=PromptTemplate.from_template(\"Desculpe, não entendi: {input}\")\n",
    ")\n",
    "\n",
    "destination_chains = {\n",
    "    \"roteiro-viagem\": itinerary_chain,\n",
    "    \"logistica-transporte\": logistics_chain,\n",
    "    \"info-local\": local_info_chain,\n",
    "    \"traducao-idiomas\": translation_chain,\n",
    "}\n",
    "\n",
    "\n",
    "# Roteador baseado em chave\n",
    "\n",
    "router = RouterRunnable(\n",
    "    get_destination=lambda input: input.get(\"categoria\", \"\"),\n",
    "    destinations=destination_chains,\n",
    "    default=default_chain\n",
    ")\n",
    "\n",
    "\n",
    "# o erro acontece nesse RouterChain, onde ele não consegue resolver a importação de jeito nenhum.\n",
    "multi_chain = RouterChain(\n",
    "    router_chain=router_chain,\n",
    "    destination_chains=destination_chains,\n",
    "    default_chain=default_chain\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c896c3e",
   "metadata": {},
   "source": [
    "### Função de roteamento simples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f06dd9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def route_input(user_input):\n",
    "    if \"viagem\" in user_input.lower():\n",
    "        return itinerary_chain.invoke({\"input\": user_input})\n",
    "    elif \"transporte\" in user_input.lower():\n",
    "        return logistics_chain.invoke({\"input\": user_input})\n",
    "    elif \"local\" in user_input.lower():\n",
    "        return local_info_chain.invoke({\"input\": user_input})\n",
    "    elif \"traduzir\" in user_input.lower() or \"idioma\" in user_input.lower():\n",
    "        return translation_chain.invoke({\"input\": user_input})\n",
    "    else:\n",
    "        return default_chain.invoke({\"input\": user_input})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da00b20c",
   "metadata": {},
   "source": [
    "### aqui é para garantir que a resposta seja tratada corretamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af5a840",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_answer(response):\n",
    "    if isinstance(response, str):\n",
    "        return response\n",
    "    elif isinstance(response, dict):\n",
    "        # Tenta encontrar a chave mais provável\n",
    "        for key in [\"answer\", \"text\", \"result\", \"output\"]:\n",
    "            if key in response:\n",
    "                return response[key]\n",
    "        # Se não encontrar nenhuma chave conhecida, retorna tudo\n",
    "        return str(response)\n",
    "    elif hasattr(response, \"content\"):\n",
    "        return response.content\n",
    "    elif hasattr(response, \"text\"):\n",
    "        return response.text\n",
    "    else:\n",
    "        return str(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd55e9c2",
   "metadata": {},
   "source": [
    "### Função de entrada e loop interativo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca03ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_question(question):\n",
    "    response = route_input(question)\n",
    "    answer = extract_answer(response)\n",
    "    print(f\"\\nPergunta: {question}\")\n",
    "    print(f\"Resposta: {answer}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf34d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testes iniciais\n",
    "testes = [\n",
    "    \"Sugira um roteiro cultural de 3 dias em Paris.\",\n",
    "    \"Como chegar ao Coliseu?\",\n",
    "    \"Quais são os melhores restaurantes veganos em Tóquio?\",\n",
    "    \"Como se diz 'onde fica o hotel?' em francês?\"\n",
    "]\n",
    "\n",
    "for pergunta in testes:\n",
    "    process_question(pergunta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "525c024e",
   "metadata": {},
   "source": [
    "### Interface interativa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58360b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    question = input(\"\\nDigite sua pergunta sobre turismo (ou 'sair' para encerrar): \")\n",
    "    if question.lower() == \"sair\":\n",
    "        break\n",
    "    process_question(question)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "835118f6",
   "metadata": {},
   "source": [
    "## Limpeza (Opcional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868c79aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para deletar o índice do Pinecone (use com cautela!)\n",
    "# pc.delete_index(index_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
